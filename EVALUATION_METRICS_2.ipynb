{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Jzj5uAvgNrv",
        "outputId": "41c9e2d6-3cb7-41db-8d26-acbf50e3645d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7500\n",
            "Precision: 0.7500\n",
            "Recall (Sensitivity): 0.7500\n",
            "Specificity: 0.7500\n",
            "F1 Score: 0.7500\n",
            "Balanced Accuracy: 0.7500\n",
            "AUC: 0.9375\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "def classification_metrics(y_true, y_pred, y_scores=None):\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
        "    TN = np.sum((y_true == 0) & (y_pred == 0))\n",
        "    FP = np.sum((y_true == 0) & (y_pred == 1))\n",
        "    FN = np.sum((y_true == 1) & (y_pred == 0))\n",
        "\n",
        "    accuracy = (TP + TN) / len(y_true)\n",
        "    precision = TP / (TP + FP) if (TP + FP) else 0\n",
        "    recall = TP / (TP + FN) if (TP + FN) else 0\n",
        "    specificity = TN / (TN + FP) if (TN + FP) else 0\n",
        "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) else 0\n",
        "    balanced_acc = (recall + specificity) / 2\n",
        "\n",
        "\n",
        "    auc = roc_auc_score(y_true, y_scores) if y_scores is not None else None\n",
        "\n",
        "    return {\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall (Sensitivity)': recall,\n",
        "        'Specificity': specificity,\n",
        "        'F1 Score': f1,\n",
        "        'Balanced Accuracy': balanced_acc,\n",
        "        'AUC': auc\n",
        "    }\n",
        "\n",
        "\n",
        "y_true = [1, 0, 1, 1, 0, 1, 0, 0]\n",
        "y_pred = [1, 0, 1, 0, 0, 1, 1, 0]\n",
        "y_scores = [0.9, 0.1, 0.85, 0.4, 0.3, 0.8, 0.7, 0.2]\n",
        "\n",
        "metrics = classification_metrics(y_true, y_pred, y_scores)\n",
        "\n",
        "for key, value in metrics.items():\n",
        "    print(f\"{key}: {value:.4f}\" if value is not None else f\"{key}: N/A\")\n"
      ]
    }
  ]
}